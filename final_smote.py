import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ----------------------------------------------------
# 1. è³‡æ–™è¼‰å…¥èˆ‡æº–å‚™
# ----------------------------------------------------
file_path = "pokemon_newtype.csv"

encodings = ["utf-8", "utf-8-sig", "cp950", "big5", "cp1252"]
df = None
used_encoding = None

for enc in encodings:
    try:
        df = pd.read_csv(file_path, encoding=enc)
        used_encoding = enc
        break
    except UnicodeDecodeError:
        continue

if df is None:
    raise RuntimeError("è®€å– CSV å¤±æ•—ï¼šè«‹ç¢ºèªæª”æ¡ˆç·¨ç¢¼æˆ–æª”æ¡ˆæ˜¯å¦æå£ã€‚")

print(f"âœ… CSV è®€å–æˆåŠŸï¼š{file_path} (encoding={used_encoding})")

df.columns = df.columns.str.strip()

# æŒ‡å®šç‰¹å¾µèˆ‡æ¨™ç±¤
feature_cols = ["HP", "Attack", "Defense", "Sp. Atk", "Sp. Def", "Speed"]
target_col = "Type_group"

missing = [c for c in feature_cols + [target_col] if c not in df.columns]
if missing:
    print("âŒ ä½ çš„ CSV æ¬„ä½å¦‚ä¸‹ï¼š")
    print(df.columns.tolist())
    raise KeyError(f"ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing}\nè«‹ç¢ºèª CSV æ¬„ä½åç¨±æ˜¯å¦å®Œå…¨ä¸€è‡´ã€‚")

X = df[feature_cols].copy()
y = df[target_col].copy()

# å»æ‰ç¼ºå€¼
before = len(df)
data = pd.concat([X, y], axis=1).dropna()
after = len(data)
if after != before:
    print(f"âš ï¸ åµæ¸¬åˆ°ç¼ºå€¼ï¼Œå·²ç§»é™¤ {before - after} ç­†è³‡æ–™ï¼ˆå‰© {after} ç­†ï¼‰")

X = data[feature_cols]
y = data[target_col]

print("\nğŸ“Œ é¡åˆ¥åˆ†ä½ˆï¼ˆå…¨éƒ¨è³‡æ–™ï¼‰")
print(y.value_counts().sort_index())

# ----------------------------------------------------
# 2. åˆ‡åˆ†è¨“ç·´é›†èˆ‡æ¸¬è©¦é›†ï¼ˆTest æ°¸é ä¸åƒèˆ‡èª¿åƒï¼‰
# ----------------------------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("\nğŸ“Œ é¡åˆ¥åˆ†ä½ˆï¼ˆTrainï¼‰")
print(pd.Series(y_train).value_counts().sort_index())
print("\nğŸ“Œ é¡åˆ¥åˆ†ä½ˆï¼ˆTestï¼‰")
print(pd.Series(y_test).value_counts().sort_index())

# ----------------------------------------------------
# 3. å»ºç«‹ Pipeline + GridSearchCV èª¿è¶…åƒæ•¸
# ----------------------------------------------------
pipe = Pipeline(steps=[
    ("scaler", StandardScaler()),
    ("logreg", LogisticRegression(
        solver="lbfgs",
        max_iter=5000,
        random_state=42
    ))
])

# ä½ çœŸæ­£èƒ½èª¿ã€ä¹Ÿæœ€æœ‰æ•ˆçš„ LR è¶…åƒæ•¸ä¸»è¦æ˜¯ C èˆ‡ class_weight
param_grid = {
    "logreg__C": [0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10, 20],
    "logreg__class_weight": [None, "balanced"]
}

# äº¤å‰é©—è­‰ï¼ˆåˆ†å±¤ï¼‰é¿å…æŸæŠ˜æŸé¡å¤ªå°‘
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# æƒ³è¡ã€Œæº–ç¢ºç‡ã€å°±ç”¨ accuracyï¼›å¦‚æœè€å¸«åœ¨æ„å°é¡åˆ¥ï¼Œç”¨ f1_macro æ›´åˆç†
grid = GridSearchCV(
    estimator=pipe,
    param_grid=param_grid,
    scoring="accuracy",   # ä½ è¦æ›´å…¬å¹³å¯æ”¹æˆ "f1_macro"
    cv=cv,
    n_jobs=-1,
    verbose=0
)

grid.fit(X_train, y_train)

best_model = grid.best_estimator_
print("\n" + "="*60)
print("âœ… GridSearch å®Œæˆ")
print("Best Params:", grid.best_params_)
print(f"Best CV Score ({grid.scoring}): {grid.best_score_:.4f}")
print("="*60)

# ----------------------------------------------------
# 4. ç”¨æœ€ä½³æ¨¡å‹è©•ä¼° Train / Testï¼ˆæ˜ç¢ºåˆ†é–‹ï¼‰
# ----------------------------------------------------
def evaluate(split_name, X_split, y_split, model):
    y_pred = model.predict(X_split)
    acc = accuracy_score(y_split, y_pred)
    print("\n" + "="*60)
    print(f"Classification Report ({split_name})")
    print("="*60)
    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_split, y_pred, digits=4))
    return y_pred

y_pred_train = evaluate("Train Set", X_train, y_train, best_model)
y_pred_test  = evaluate("Test Set",  X_test,  y_test,  best_model)

# ----------------------------------------------------
# 5. ä¿‚æ•¸è¼¸å‡ºï¼ˆLogistic Regression æ‰æœ‰ï¼‰
# ----------------------------------------------------
logreg = best_model.named_steps["logreg"]
coef_df = pd.DataFrame(
    logreg.coef_,
    columns=feature_cols,
    index=[f"Class {c}" for c in logreg.classes_]
)
print("\nModel Coefficients:\n", coef_df)

coef_df.to_csv("final_coefficients.csv", encoding="utf-8-sig")
print("\nâœ… ä¿‚æ•¸å·²å„²å­˜è‡³ final_coefficients.csv (utf-8-sig)")

# ----------------------------------------------------
# 6. æ··æ·†çŸ©é™£ï¼ˆTestï¼‰ï¼šCount + Normalized by True Label
# ----------------------------------------------------
classes = np.sort(y.unique())
cm = confusion_matrix(y_test, y_pred_test, labels=classes)

plt.figure(figsize=(9, 7))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=classes, yticklabels=classes)
plt.title("Confusion Matrix (Test Set) - Count", fontsize=16, fontweight="bold")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.savefig("confusion_matrix_count.png", dpi=300)
print("\nâœ… å·²è¼¸å‡ºï¼šconfusion_matrix_count.png")

# æ¯åˆ—æ­£è¦åŒ–ï¼ˆæ¯ä¸€åˆ—åŠ ç¸½=1ï¼‰
cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)
cm_norm = np.nan_to_num(cm_norm)

plt.figure(figsize=(9, 7))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Blues",
            xticklabels=classes, yticklabels=classes, vmin=0, vmax=1)
plt.title("Confusion Matrix (Test Set) - Normalized by True Label", fontsize=16, fontweight="bold")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.tight_layout()
plt.savefig("confusion_matrix_normalized.png", dpi=300)
print("âœ… å·²è¼¸å‡ºï¼šconfusion_matrix_normalized.png")
